{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tabulate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "USERS = [\"David\", \"Jeff\", \"Kay\", \"Sara\", \"Tana\"]\n",
    "METRICS = [\"BLEU\", \"Rouge\", \"Mauve\"]\n",
    "METRIC_NAMES = {\n",
    "    \"BLEU\": \"BLEU\",\n",
    "    \"Rouge\": \"rougeLsum_fmeasure\",\n",
    "    \"Mauve\": \"MAUVE\"\n",
    "\n",
    "}\n",
    "MODEL_TYPES = [\"FFT\", \"RoSA\", \"LoRA\"]\n",
    "\n",
    "COLUMNS = [\"model\", \"user\", \"model_type\", \"metric\", \"RAFT\", \"RAG\", \"score\", \"seed\", \"metadata\"]\n",
    "\n",
    "BASE_MODEL_RESULTS = \"/nfs/scistore19/alistgrp/anicolic/repos/PanzaMailFork/results/logs_base_models\"\n",
    "\n",
    "# GENERATIVE_MODEL = \"Phi-3-mini-4k-instruct\"\n",
    "# GENERATIVE_MODEL = \"Mistral-7B-Instruct-v0.2\"\n",
    "GENERATIVE_MODEL = \"Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280248/3150942016.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping panza_david_anonymous_llama3_bf16-bs8-fft-lr1e-05-epochs3-wu20-seed41-PREAMBLE-10783 because of 'EVAL/BLEU-mean'\n",
      "Skipping panza_david_anonymous_llama3_bf16-bs8-fft-lr1e-05-epochs3-wu20-seed41-PREAMBLE-10783 because of 'EVAL/rougeLsum_fmeasure-mean'\n",
      "Skipping panza_david_anonymous_llama3_bf16-bs8-fft-lr1e-05-epochs3-wu20-seed41-PREAMBLE-10783 because of 'EVAL/MAUVE-mean'\n",
      "Skipping panza_david_anonymous_llama3_bf16-bs8-fft-lr1e-05-epochs3-wu20-seed41-PREAMBLE-10783 because of 'EVAL/BLEU-RAG-mean'\n",
      "Skipping panza_david_anonymous_llama3_bf16-bs8-fft-lr1e-05-epochs3-wu20-seed41-PREAMBLE-10783 because of 'EVAL/rougeLsum_fmeasure-RAG-mean'\n",
      "Skipping panza_david_anonymous_llama3_bf16-bs8-fft-lr1e-05-epochs3-wu20-seed41-PREAMBLE-10783 because of 'EVAL/MAUVE-RAG-mean'\n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280248/3150942016.py:63: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, load_wandb_project_runs(project_name)])\n",
      "/tmp/ipykernel_280248/3150942016.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280248/3150942016.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280248/3150942016.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280248/3150942016.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "      model   user model_type metric   RAFT    RAG     score seed metadata\n",
      "0    Llama3  David       LoRA   BLEU   True  False  0.221758   43     None\n",
      "1    Llama3  David       LoRA  Rouge   True  False  0.376480   43     None\n",
      "2    Llama3  David       LoRA  Mauve   True  False  0.130876   43     None\n",
      "3    Llama3  David       LoRA   BLEU   True   True  0.259400   43     None\n",
      "4    Llama3  David       LoRA  Rouge   True   True  0.407788   43     None\n",
      "..      ...    ...        ...    ...    ...    ...       ...  ...      ...\n",
      "103  Llama3   Tana        FFT  Rouge  False  False  0.358420   41     None\n",
      "104  Llama3   Tana        FFT  Mauve  False  False  0.801999   41     None\n",
      "105  Llama3   Tana        FFT   BLEU  False   True  0.242749   41     None\n",
      "106  Llama3   Tana        FFT  Rouge  False   True  0.328652   41     None\n",
      "107  Llama3   Tana        FFT  Mauve  False   True  0.902079   41     None\n",
      "\n",
      "[534 rows x 9 columns]\n",
      "      model   user model_type metric   RAFT    RAG     score  score_std\n",
      "0    Llama3  David        FFT   BLEU  False  False  0.277729   0.023865\n",
      "1    Llama3  David        FFT   BLEU  False   True  0.300206   0.011240\n",
      "2    Llama3  David        FFT   BLEU   True  False  0.298981   0.010539\n",
      "3    Llama3  David        FFT   BLEU   True   True  0.309769   0.011525\n",
      "4    Llama3  David        FFT  Mauve  False  False  0.996198   0.000738\n",
      "..      ...    ...        ...    ...    ...    ...       ...        ...\n",
      "175  Llama3   Tana       RoSA  Mauve   True   True  0.904827   0.055821\n",
      "176  Llama3   Tana       RoSA  Rouge  False  False  0.352222   0.001696\n",
      "177  Llama3   Tana       RoSA  Rouge  False   True  0.339849   0.008015\n",
      "178  Llama3   Tana       RoSA  Rouge   True  False  0.349359   0.008574\n",
      "179  Llama3   Tana       RoSA  Rouge   True   True  0.367309   0.000798\n",
      "\n",
      "[180 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_config_from_run_name(run_name):\n",
    "    user = [u for u in USERS if u.lower() in run_name][0]\n",
    "    model_type = [m for m in MODEL_TYPES if m.lower() in run_name][0]\n",
    "    if model_type == \"RoSA\" and \"lr0.0-epochs\" in run_name:\n",
    "        model_type = \"LoRA\"\n",
    "    raft = \"RAFT\" in run_name\n",
    "    seed = int(run_name.split(\"seed\")[-1].split(\"-\")[0])\n",
    "    return user, model_type, raft, seed\n",
    "\n",
    "\n",
    "def load_wandb_project_runs(project_name):\n",
    "    results_df = pd.DataFrame(columns=COLUMNS)\n",
    "    runs = api.runs(project_name)\n",
    "    for run in runs:\n",
    "        if run.summary[\"_timestamp\"] < 1717813799.4198122:\n",
    "            continue  # Skip older runs\n",
    "        user, model_type, raft, seed = extract_config_from_run_name(run.name)\n",
    "        if user in [\"David\", \"Jeff\"] and \"lr0.0001\" in run.name:\n",
    "            continue\n",
    "        if user in [\"Kay\", \"Sara\", \"Tana\"] and \"lr0.0001\" not in run.name:\n",
    "            continue\n",
    "        summary = run.summary._json_dict\n",
    "        for rag in [False, True]:\n",
    "            for metric in METRICS:\n",
    "                try:\n",
    "                    score = summary[f\"EVAL/{METRIC_NAMES[metric]}{'-RAG' if rag else ''}-mean\"]\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping {run.name} because of {e}\")\n",
    "                    continue\n",
    "                results_df = results_df._append({\n",
    "                    \"model\": \"Llama3\",\n",
    "                    \"user\": user,\n",
    "                    \"model_type\": model_type,\n",
    "                    \"metric\": metric,\n",
    "                    \"RAFT\": raft,\n",
    "                    \"RAG\": rag,\n",
    "                    \"score\": score,\n",
    "                    \"seed\": seed,\n",
    "                    \"metadata\": None\n",
    "                }, ignore_index=True)\n",
    "\n",
    "    print(len(results_df))\n",
    "    return results_df\n",
    "\n",
    "# all_projects = [\n",
    "#     (\"david\", \"diverse-vit/panza-david_anonymous-Phi3-June8\"),\n",
    "#     (\"jeff\", \"diverse-vit/panza-jeff_johnson-Phi3-June8\"),\n",
    "#     (\"kay\", \"diverse-vit/panza-kay_brown-Phi3-June8\"),\n",
    "#     (\"sara\", \"diverse-vit/panza-shackleton_sara-Phi3-June8\"),\n",
    "#     (\"tana\", \"diverse-vit/panza-tana_williams-Phi3-June8\"),\n",
    "# ]\n",
    "\n",
    "all_projects = [\n",
    "    (\"david\", \"diverse-vit/panza-david_anonymous-llama3-June9\"),\n",
    "    (\"jeff\", \"diverse-vit/panza-jeff_johnson-llama3-June9\"),\n",
    "    (\"kay\", \"diverse-vit/panza-kay_brown-llama3-June9\"),\n",
    "    (\"sara\", \"diverse-vit/panza-shackleton_sara-llama3-June9\"),\n",
    "    (\"tana\", \"diverse-vit/panza-tana_williams-llama3-June9\"),\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(columns=COLUMNS)\n",
    "for _, project_name in all_projects:\n",
    "    results_df = pd.concat([results_df, load_wandb_project_runs(project_name)])\n",
    "\n",
    "# results_df = load_wandb_project_runs(\"diverse-vit/panza-jeff_johnson-Phi3-June8\")\n",
    "\n",
    "print(results_df)\n",
    "results_df = results_df.groupby(['model', 'user', 'model_type', 'metric', 'RAFT', 'RAG']).agg({'score': ['mean', 'std']}).reset_index()\n",
    "results_df.columns = ['model', 'user', 'model_type', 'metric', 'RAFT', 'RAG', 'score', 'score_std']\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280248/3402434779.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = results_df._append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model   user model_type metric   RAFT    RAG     score  \\\n",
      "0   Meta-Llama-3-8B-Instruct  David       Base   BLEU  False  False  0.083463   \n",
      "1   Meta-Llama-3-8B-Instruct  David       Base   BLEU  False   True  0.107134   \n",
      "2   Meta-Llama-3-8B-Instruct  David       Base  Mauve  False  False  0.009092   \n",
      "3   Meta-Llama-3-8B-Instruct  David       Base  Mauve  False   True  0.017172   \n",
      "4   Meta-Llama-3-8B-Instruct  David       Base  Rouge  False  False  0.181028   \n",
      "5   Meta-Llama-3-8B-Instruct  David       Base  Rouge  False   True  0.212159   \n",
      "6   Meta-Llama-3-8B-Instruct   Jeff       Base   BLEU  False  False  0.108474   \n",
      "7   Meta-Llama-3-8B-Instruct   Jeff       Base   BLEU  False   True  0.115027   \n",
      "8   Meta-Llama-3-8B-Instruct   Jeff       Base  Mauve  False  False  0.004072   \n",
      "9   Meta-Llama-3-8B-Instruct   Jeff       Base  Mauve  False   True  0.005002   \n",
      "10  Meta-Llama-3-8B-Instruct   Jeff       Base  Rouge  False  False  0.181796   \n",
      "11  Meta-Llama-3-8B-Instruct   Jeff       Base  Rouge  False   True  0.188047   \n",
      "12  Meta-Llama-3-8B-Instruct    Kay       Base   BLEU  False  False  0.112644   \n",
      "13  Meta-Llama-3-8B-Instruct    Kay       Base   BLEU  False   True  0.120763   \n",
      "14  Meta-Llama-3-8B-Instruct    Kay       Base  Mauve  False  False  0.005397   \n",
      "15  Meta-Llama-3-8B-Instruct    Kay       Base  Mauve  False   True  0.004350   \n",
      "16  Meta-Llama-3-8B-Instruct    Kay       Base  Rouge  False  False  0.186326   \n",
      "17  Meta-Llama-3-8B-Instruct    Kay       Base  Rouge  False   True  0.197343   \n",
      "18  Meta-Llama-3-8B-Instruct   Sara       Base   BLEU  False  False  0.144333   \n",
      "19  Meta-Llama-3-8B-Instruct   Sara       Base   BLEU  False   True  0.151389   \n",
      "20  Meta-Llama-3-8B-Instruct   Sara       Base  Mauve  False  False  0.004072   \n",
      "21  Meta-Llama-3-8B-Instruct   Sara       Base  Mauve  False   True  0.004072   \n",
      "22  Meta-Llama-3-8B-Instruct   Sara       Base  Rouge  False  False  0.229756   \n",
      "23  Meta-Llama-3-8B-Instruct   Sara       Base  Rouge  False   True  0.233085   \n",
      "24  Meta-Llama-3-8B-Instruct   Tana       Base   BLEU  False  False  0.131896   \n",
      "25  Meta-Llama-3-8B-Instruct   Tana       Base   BLEU  False   True  0.148950   \n",
      "26  Meta-Llama-3-8B-Instruct   Tana       Base  Mauve  False  False  0.005630   \n",
      "27  Meta-Llama-3-8B-Instruct   Tana       Base  Mauve  False   True  0.004793   \n",
      "28  Meta-Llama-3-8B-Instruct   Tana       Base  Rouge  False  False  0.209555   \n",
      "29  Meta-Llama-3-8B-Instruct   Tana       Base  Rouge  False   True  0.227428   \n",
      "\n",
      "       score_std  \n",
      "0   2.069311e-03  \n",
      "1   1.961894e-03  \n",
      "2   0.000000e+00  \n",
      "3   1.399480e-02  \n",
      "4   3.827636e-04  \n",
      "5   6.897356e-03  \n",
      "6   1.798030e-03  \n",
      "7   2.179604e-03  \n",
      "8   2.294823e-18  \n",
      "9   5.375472e-04  \n",
      "10  9.492621e-04  \n",
      "11  3.290595e-03  \n",
      "12  8.305298e-04  \n",
      "13  1.644443e-03  \n",
      "14  6.634000e-04  \n",
      "15  4.813672e-04  \n",
      "16  5.319862e-04  \n",
      "17  3.620493e-03  \n",
      "18  5.206382e-03  \n",
      "19  1.082842e-03  \n",
      "20  8.673617e-19  \n",
      "21  1.502315e-18  \n",
      "22  2.983333e-03  \n",
      "23  1.680549e-03  \n",
      "24  2.593957e-03  \n",
      "25  1.994832e-03  \n",
      "26  1.524353e-04  \n",
      "27  1.062297e-18  \n",
      "28  2.246066e-03  \n",
      "29  1.446981e-03  \n"
     ]
    }
   ],
   "source": [
    "def extract_config_from_results_name(file_name):\n",
    "    user = [u for u in USERS if u.lower() in file_name][0]\n",
    "    seed = int(file_name.split(\"seed\")[-1].split(\"_\")[0])\n",
    "    rag = \"RAG\" in file_name\n",
    "    return user, seed, rag\n",
    "\n",
    "\n",
    "def load_base_model_results(results_path):\n",
    "    results_df = pd.DataFrame(columns=COLUMNS)\n",
    "    for file_name in os.listdir(results_path):\n",
    "        if GENERATIVE_MODEL in file_name and \"summary\" in file_name: # and file_name.endswith(\".json\"):\n",
    "            user, seed, rag = extract_config_from_results_name(file_name)\n",
    "            with open(os.path.join(results_path, file_name)) as f:\n",
    "                results = json.load(f)\n",
    "            for metric in METRICS:\n",
    "                score = results[\"means\"][METRIC_NAMES[metric]]\n",
    "                results_df = results_df._append({\n",
    "                    \"model\": GENERATIVE_MODEL,\n",
    "                    \"user\": user,\n",
    "                    \"model_type\": \"Base\",\n",
    "                    \"metric\": metric,\n",
    "                    \"RAFT\": False,\n",
    "                    \"RAG\": rag,\n",
    "                    \"score\": score,\n",
    "                    \"seed\": seed,\n",
    "                    \"metadata\": None\n",
    "                }, ignore_index=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "base_results_df = load_base_model_results(BASE_MODEL_RESULTS)\n",
    "base_results_df = base_results_df.groupby(['model', 'user', 'model_type', 'metric', 'RAFT', 'RAG']).agg({'score': ['mean', 'std']}).reset_index()\n",
    "base_results_df.columns = ['model', 'user', 'model_type', 'metric', 'RAFT', 'RAG', 'score', 'score_std']\n",
    "print(base_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pretrained', 0.0834630674868822, 0.18102784951527914, 0.009091640952813812, 0.1084743357270725, 0.1817964946403522, 0.0040720962619612555, 0.11264385019118588, 0.18632575752282585, 0.005397102711700084, 0.14433266845132622, 0.22975609025784902, 0.0040720962619612555, 0.13189641830940993, 0.2095547671252418, 0.005630289023601111]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "['Pretrained-RAG', 0.10713399892052015, 0.2121585038304329, 0.01717154339118201, 0.11502747702621674, 0.18804668406991995, 0.005001847776876451, 0.12076302043472727, 0.1973427694497837, 0.00435001375085826, 0.15138914164687908, 0.23308546656653994, 0.004072096261961256, 0.14894982898563502, 0.22742815637251454, 0.004792967776141999]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "['FFT', 0.27772917898371813, 0.46040987253189086, 0.9961982169052762, 0.1655147774141539, 0.2822615600573693, 0.7581330699498365, 0.19697140439637695, 0.29491189923309896, 0.8625331304971033, 0.2606361812158866, 0.3563251865406831, 0.8586937629373148, 0.2561484849062427, 0.35824804924916304, 0.8594281538794633]\n",
      "[False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False]\n",
      "['FFT-RAG', 0.3002056972899785, 0.44877118209997807, 0.9841179815392797, 0.16613185661471241, 0.2657173516322649, 0.7786307393602736, 0.19030958173917265, 0.2832719518251165, 0.9331732056043848, 0.2418376566043922, 0.336658961387972, 0.8517948104770289, 0.23764692117159333, 0.32653945801957024, 0.8984408502400355]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "['FFT-RAFT', 0.2989809370040894, 0.47640510916709894, 0.9966581082705835, 0.16420458602573484, 0.2793687935629787, 0.715423727581407, 0.19206813981280127, 0.28512498470782127, 0.890684251482034, 0.2533620784935054, 0.35706431386726245, 0.9135468392509921, 0.26649274777320814, 0.36300958265062605, 0.9027964929487352]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "['FFT-RAFT-RAG', 0.30976919713119666, 0.4941444494326909, 0.9846233171822756, 0.1865158933910254, 0.29679375894136667, 0.8242190493117069, 0.1841803046166509, 0.2810019255546784, 0.940908158181399, 0.2633288690986644, 0.3603461035660335, 0.8262385881959401, 0.2783143302524205, 0.3724848117368917, 0.8762918482443446]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False]\n",
      "['RoSA', 0.31176177327831583, 0.4883435316880544, 0.998611288918628, 0.16390702127354903, 0.2845421957227496, 0.8059144353382317, 0.20206449169846666, 0.29262694454303495, 0.8975067043527872, 0.25983743567152745, 0.35500465152519095, 0.8720096480940055, 0.2603749860181346, 0.35222236785505495, 0.9481688163411223]\n",
      "[False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False]\n",
      "['RoSA-RAG', 0.23571329372934993, 0.38282405505577727, 0.9818442239948754, 0.16588312203051486, 0.2656538504421307, 0.7863609490154824, 0.1842698033519641, 0.26865557933019263, 0.9629845656443701, 0.24344106890882056, 0.33780007270120443, 0.9449438860925071, 0.25291887768712296, 0.3398490460323436, 0.9698849450266267]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n",
      "['RoSA-RAFT', 0.3208034835507472, 0.49149633944034576, 0.9913667421109168, 0.1659186538437457, 0.29076118224350983, 0.8226460537994975, 0.2009449406587346, 0.28950036165338977, 0.8954522808104475, 0.26764249427887127, 0.35954225070419765, 0.7628869899884424, 0.25156278231519363, 0.349359144545382, 0.8141432358739276]\n",
      "[False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "['RoSA-RAFT-RAG', 0.34644997283816337, 0.5090061875184376, 0.9999840258349764, 0.19230456699865464, 0.3052737140854777, 0.8665439975771528, 0.19576139612709756, 0.2910200051480421, 0.9725445948315857, 0.2651490741054572, 0.36210689970425197, 0.8893264001799129, 0.27672336867354236, 0.36730939063376616, 0.904826622758682]\n",
      "[False, True, True, True, True, True, True, False, False, False, False, True, False, False, False, False]\n",
      "['LoRA', 0.259840682707727, 0.40142493993043904, 0.6796654079158342, 0.1670680145004606, 0.26961518471425244, 0.22445388440756417, 0.18393886277745305, 0.2694654491022919, 0.9785865298765654, 0.24721506897781398, 0.3507314833501975, 0.9210185630566738, 0.23869435075236348, 0.3288411370123781, 0.8967884041547337]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "['LoRA-RAG', 0.25675421439111235, 0.40615738540887836, 0.9215851166387377, 0.15912684633012972, 0.25332665036237517, 0.48131983448125376, 0.18067459779477857, 0.26740133131129873, 0.9678944762966268, 0.22993277437275364, 0.3274256311711811, 0.9688751906245607, 0.23260055331601984, 0.3120543749481883, 0.9416019547108645]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False]\n",
      "['LoRA-RAFT', 0.24271505676209926, 0.3914020223418872, 0.41153042637281656, 0.16472677391966298, 0.2666586301787648, 0.1490886937407805, 0.1871338650623026, 0.2763897990807891, 0.9868771474310901, 0.24491963493443714, 0.34054731517320586, 0.9064131551234587, 0.24296608134422315, 0.32869676622517763, 0.8927266003075413]\n",
      "[False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False]\n",
      "['LoRA-RAFT-RAG', 0.24571501021583875, 0.40389900366465253, 0.8989942242953615, 0.16679779563676353, 0.2616488996319213, 0.5469160469324549, 0.18451700770917037, 0.2703104784746689, 0.9421597825988082, 0.2521433575477983, 0.3493485063669228, 0.9087913740914275, 0.26234966049794045, 0.35296700411431847, 0.8543612732256927]\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "def get_mock_results():\n",
    "    df = pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "    for user in USERS:\n",
    "        for model_type in MODEL_TYPES:\n",
    "            for metric in METRICS:\n",
    "                for rag in [False, True]:\n",
    "                    for raft in [False, True]:\n",
    "                        df = df._append(\n",
    "                            {\n",
    "                                \"model\": \"model\",\n",
    "                                \"user\": user,\n",
    "                                \"model_type\": model_type,\n",
    "                                \"metric\": metric,\n",
    "                                \"RAFT\": raft,\n",
    "                                \"RAG\": rag,\n",
    "                                \"score\": random.random(),\n",
    "                                \"metadata\": None,\n",
    "                            },\n",
    "                            ignore_index=True,\n",
    "                        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_all_results_table(results_df, base_results_df=None):\n",
    "    table = []\n",
    "    table_bold = []\n",
    "    if base_results_df is not None:\n",
    "        for rag in [False, True]:\n",
    "            rag_str = \"-RAG\" if rag else \"\"\n",
    "            model_str = f\"Pretrained{rag_str}\"\n",
    "            line = [model_str]\n",
    "            line_bold = [False]\n",
    "            for user in USERS:\n",
    "                for metric in METRICS:\n",
    "                    try:\n",
    "                        score = base_results_df[\n",
    "                            (base_results_df[\"user\"] == user)\n",
    "                            & (base_results_df[\"metric\"] == metric)\n",
    "                            & (base_results_df[\"RAG\"] == rag)\n",
    "                        ][\"score\"].values[0]\n",
    "                        # best_score = base_results_df[\n",
    "                        #     (base_results_df[\"user\"] == user)\n",
    "                        #     & (base_results_df[\"metric\"] == metric)][\"score\"].max()\n",
    "                        # if score == best_score:\n",
    "                        #     line_bold.append(True)\n",
    "                        # else:\n",
    "                        #     line_bold.append(False)\n",
    "                        line_bold.append(False)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        score = \"-\"\n",
    "                        line_bold.append(False)\n",
    "                    line.append(score)\n",
    "            table.append(line)\n",
    "            table_bold.append(line_bold)\n",
    "\n",
    "    for model_type in MODEL_TYPES:\n",
    "        for raft in [False, True]:\n",
    "            for rag in [False, True]:\n",
    "                # Create line for given model type and raft\n",
    "                filtered_df = results_df[\n",
    "                    (results_df[\"model_type\"] == model_type)\n",
    "                    & (results_df[\"RAFT\"] == raft)\n",
    "                    & (results_df[\"RAG\"] == rag)\n",
    "                ]\n",
    "                raft_str = \"-RAFT\" if raft else \"\"\n",
    "                rag_str = \"-RAG\" if rag else \"\"\n",
    "                model_str = f\"{model_type}{raft_str}{rag_str}\"\n",
    "                line = [model_str]\n",
    "                line_bold = [False]\n",
    "                for user in USERS:\n",
    "                    for metric in METRICS:\n",
    "                        try:\n",
    "                            score = filtered_df[\n",
    "                                (filtered_df[\"user\"] == user) & (filtered_df[\"metric\"] == metric)\n",
    "                            ][\"score\"].values[0]\n",
    "                            best_score = results_df[(results_df[\"user\"] == user) & (results_df[\"metric\"] == metric)][\"score\"].max()\n",
    "                            # best_score = results_df[(results_df[\"user\"] == user) & (results_df[\"metric\"] == metric) & (results_df[\"model_type\"] == model_type)][\"score\"].max()\n",
    "                            if score == best_score:\n",
    "                                line_bold.append(True)\n",
    "                            else:\n",
    "                                line_bold.append(False)\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            score = \"-\"\n",
    "                            line_bold.append(False)\n",
    "                        line.append(score)\n",
    "                table.append(line)\n",
    "                table_bold.append(line_bold)\n",
    "    return table, table_bold\n",
    "\n",
    "# mock_df = get_mock_results()\n",
    "table, table_bold = create_all_results_table(results_df, base_results_df)\n",
    "for i, line in enumerate(table):\n",
    "    print(line)\n",
    "    print(table_bold[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\documentclass{article}%\n",
      "\\usepackage[T1]{fontenc}%\n",
      "\\usepackage[utf8]{inputenc}%\n",
      "\\usepackage{lmodern}%\n",
      "\\usepackage{textcomp}%\n",
      "\\usepackage{lastpage}%\n",
      "%\n",
      "%\n",
      "%\n",
      "\\begin{document}%\n",
      "\\normalsize%\n",
      "\\begin{tabular}{l>{\\columncolor{gray!10}}c>{\\columncolor{gray!10}}c>{\\columncolor{gray!10}}cccc>{\\columncolor{gray!10}}c>{\\columncolor{gray!10}}c>{\\columncolor{gray!10}}cccc>{\\columncolor{gray!10}}c>{\\columncolor{gray!10}}c>{\\columncolor{gray!10}}c}%\n",
      "\\hline%\n",
      " &\\multicolumn{3}{c}{\\texttt{David}}&\\multicolumn{3}{c}{\\texttt{Jeff}}&\\multicolumn{3}{c}{\\texttt{Kay}}&\\multicolumn{3}{c}{\\texttt{Sara}}&\\multicolumn{3}{c}{\\texttt{Tana}}\\\\%\n",
      "\\hline%\n",
      "Method&BLEU&Rouge&Mauve&BLEU&Rouge&Mauve&BLEU&Rouge&Mauve&BLEU&Rouge&Mauve&BLEU&Rouge&Mauve\\\\%\n",
      "\\texttt{Pretrained}&$0.083$&$0.181$&$0.009$&$0.108$&$0.182$&$0.004$&$0.113$&$0.186$&$0.005$&$0.144$&$0.23$&$0.004$&$0.132$&$0.21$&$0.006$\\\\%\n",
      "\\texttt{Pretrained{-}RAG}&$0.107$&$0.212$&$0.017$&$0.115$&$0.188$&$0.005$&$0.121$&$0.197$&$0.004$&$0.151$&$0.233$&$0.004$&$0.149$&$0.227$&$0.005$\\\\%\n",
      "\\hline%\n",
      "\\texttt{FFT}&$0.278$&$0.46$&$0.996$&$0.166$&$0.282$&$0.758$&$0.197$&$\\textbf{0.295}$&$0.863$&$0.261$&$0.356$&$0.859$&$0.256$&$0.358$&$0.859$\\\\%\n",
      "\\texttt{FFT{-}RAG}&$0.3$&$0.449$&$0.984$&$0.166$&$0.266$&$0.779$&$0.19$&$0.283$&$0.933$&$0.242$&$0.337$&$0.852$&$0.238$&$0.327$&$0.898$\\\\%\n",
      "\\texttt{FFT{-}RAFT}&$0.299$&$0.476$&$0.997$&$0.164$&$0.279$&$0.715$&$0.192$&$0.285$&$0.891$&$0.253$&$0.357$&$0.914$&$0.266$&$0.363$&$0.903$\\\\%\n",
      "\\texttt{FFT{-}RAFT{-}RAG}&$0.31$&$0.494$&$0.985$&$0.187$&$0.297$&$0.824$&$0.184$&$0.281$&$0.941$&$0.263$&$0.36$&$0.826$&$\\textbf{0.278}$&$\\textbf{0.372}$&$0.876$\\\\%\n",
      "\\hline%\n",
      "\\texttt{RoSA}&$0.312$&$0.488$&$0.999$&$0.164$&$0.285$&$0.806$&$\\textbf{0.202}$&$0.293$&$0.898$&$0.26$&$0.355$&$0.872$&$0.26$&$0.352$&$0.948$\\\\%\n",
      "\\texttt{RoSA{-}RAG}&$0.236$&$0.383$&$0.982$&$0.166$&$0.266$&$0.786$&$0.184$&$0.269$&$0.963$&$0.243$&$0.338$&$0.945$&$0.253$&$0.34$&$\\textbf{0.97}$\\\\%\n",
      "\\texttt{RoSA{-}RAFT}&$0.321$&$0.491$&$0.991$&$0.166$&$0.291$&$0.823$&$0.201$&$0.29$&$0.895$&$\\textbf{0.268}$&$0.36$&$0.763$&$0.252$&$0.349$&$0.814$\\\\%\n",
      "\\texttt{RoSA{-}RAFT{-}RAG}&$\\textbf{0.346}$&$\\textbf{0.509}$&$\\textbf{1.0}$&$\\textbf{0.192}$&$\\textbf{0.305}$&$\\textbf{0.867}$&$0.196$&$0.291$&$0.973$&$0.265$&$\\textbf{0.362}$&$0.889$&$0.277$&$0.367$&$0.905$\\\\%\n",
      "\\hline%\n",
      "\\texttt{LoRA}&$0.26$&$0.401$&$0.68$&$0.167$&$0.27$&$0.224$&$0.184$&$0.269$&$0.979$&$0.247$&$0.351$&$0.921$&$0.239$&$0.329$&$0.897$\\\\%\n",
      "\\texttt{LoRA{-}RAG}&$0.257$&$0.406$&$0.922$&$0.159$&$0.253$&$0.481$&$0.181$&$0.267$&$0.968$&$0.23$&$0.327$&$\\textbf{0.969}$&$0.233$&$0.312$&$0.942$\\\\%\n",
      "\\texttt{LoRA{-}RAFT}&$0.243$&$0.391$&$0.412$&$0.165$&$0.267$&$0.149$&$0.187$&$0.276$&$\\textbf{0.987}$&$0.245$&$0.341$&$0.906$&$0.243$&$0.329$&$0.893$\\\\%\n",
      "\\texttt{LoRA{-}RAFT{-}RAG}&$0.246$&$0.404$&$0.899$&$0.167$&$0.262$&$0.547$&$0.185$&$0.27$&$0.942$&$0.252$&$0.349$&$0.909$&$0.262$&$0.353$&$0.854$\\\\%\n",
      "\\hline%\n",
      "\\end{tabular}%\n",
      "\\end{document}\n"
     ]
    }
   ],
   "source": [
    "from pylatex import Document, Section, Tabular, MultiColumn, MultiRow, Command, NoEscape\n",
    "\n",
    "def format_as_math(number):\n",
    "    \"\"\"Return number formatted as LaTeX math.\"\"\"\n",
    "    return NoEscape(f\"${number}$\")\n",
    "\n",
    "def get_colored_column():\n",
    "    \"\"\"Return a colored column formatter.\"\"\"\n",
    "    return NoEscape(\">{\\columncolor{gray!10}}\")\n",
    "\n",
    "def create_document(results_table, bold_table=None):\n",
    "    doc = Document(\"results\")\n",
    "\n",
    "    columns_format = \"\"\n",
    "    columns_format += \"l\"\n",
    "    for i, user in enumerate(USERS):\n",
    "        for metric in METRICS:\n",
    "            if i % 2 == 0:\n",
    "                columns_format += get_colored_column()\n",
    "            columns_format += \"c\"\n",
    "    # with doc.create(Tabular(\"c\" * (1 + len(USERS) * len(METRICS)))) as table:\n",
    "    with doc.create(Tabular(columns_format)) as table:\n",
    "        table.add_hline()\n",
    "\n",
    "        # Add user columns\n",
    "        user_columns = []\n",
    "        user_columns.append(\" \")\n",
    "        for i, user in enumerate(USERS):\n",
    "            if False: #i % 2 == 0:\n",
    "                user_columns.append(MultiColumn(3, align='c', data=Command('cellcolor', arguments=['gray!10'], extra_arguments=Command('texttt', user))))\n",
    "            else:\n",
    "                user_columns.append(MultiColumn(3, align='c', data=Command('texttt', user)))\n",
    "        table.add_row(user_columns)\n",
    "        table.add_hline()\n",
    "\n",
    "        # Add metric columns\n",
    "        metrics_columns = []\n",
    "        metrics_columns.append(\"Method\")\n",
    "        for user in USERS:\n",
    "            for metric in METRICS:\n",
    "                metrics_columns.append(metric)\n",
    "        table.add_row(metrics_columns)\n",
    "\n",
    "        for i, line in enumerate(results_table, 1):\n",
    "            # Add horizontal line after each model type\n",
    "            if i > 1 and results_table[i-1][0][:3] != results_table[i-2][0][:3]:\n",
    "                table.add_hline()\n",
    "\n",
    "            clean_line = []\n",
    "            for element in line:\n",
    "                if isinstance(element, str):\n",
    "                    element = Command('texttt', element)\n",
    "                    clean_line.append(element)\n",
    "                else:\n",
    "                    element = float(element)\n",
    "                    element = round(element, 3)\n",
    "                    if table_bold and table_bold[i-1][len(clean_line)]:\n",
    "                        element = NoEscape(f\"\\\\textbf{{{element}}}\")\n",
    "                    element = format_as_math(element)\n",
    "                    clean_line.append(element)\n",
    "            table.add_row(clean_line)\n",
    "\n",
    "            # Add horizontal line after each model type\n",
    "            # if i % 4 == 0:\n",
    "            #     table.add_hline()\n",
    "\n",
    "        table.add_hline()\n",
    "\n",
    "    return doc\n",
    "\n",
    "doc = create_document(table)\n",
    "print(doc.dumps())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panza-public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
